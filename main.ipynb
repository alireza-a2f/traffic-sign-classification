{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq6WkUDo3jHb"
      },
      "source": [
        "Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "ksZ4UEuM3bVb",
        "outputId": "1b1f176f-dc9c-4b71-acb0-56b74ce79137"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a82fef43-b99e-4a3b-8635-23492ac0da2a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a82fef43-b99e-4a3b-8635-23492ac0da2a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading traffic-signs-gtsrb-plus-162-custom-classes.zip to /content\n",
            "100% 15.2G/15.2G [13:14<00:00, 20.1MB/s]\n",
            "100% 15.2G/15.2G [13:14<00:00, 20.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "! rm -rf datasets\n",
        "! rm -rf sample_data\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! rm kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d daniildeltsov/traffic-signs-gtsrb-plus-162-custom-classes\n",
        "! unzip -q traffic-signs-gtsrb-plus-162-custom-classes.zip\n",
        "! mv Data_images datasets\n",
        "! rm traffic-signs-gtsrb-plus-162-custom-classes.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CERYzhJj3hKr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "with open('datasets/Test_data.csv') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        directory = 'datasets/Test/' + row['ClassId'] + '/'\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "        rename_from = 'datasets/' + row['Path']\n",
        "        rename_to = directory + row['Path'].split('/')[-1]\n",
        "        os.rename(rename_from, rename_to)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_RVXzUB3oZO"
      },
      "source": [
        "Transfomations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0H6sEOm3puw"
      },
      "outputs": [],
      "source": [
        "import albumentations as transforms\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(224, 224),\n",
        "        # transforms.SmallestMaxSize(max_size=350),\n",
        "        # transforms.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),\n",
        "        # transforms.RandomCrop(height=256, width=256),\n",
        "        # transforms.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
        "        # transforms.RandomBrightnessContrast(p=0.5),\n",
        "        # transforms.MultiplicativeNoise(multiplier=[0.5,2], per_channel=True, p=0.2),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        # transforms.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
        "        # transforms.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(224, 224),\n",
        "        # transforms.SmallestMaxSize(max_size=350),\n",
        "        # transforms.CenterCrop(height=256, width=256),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WvCOJn13tH8"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoqkLS-83tsw",
        "outputId": "3375a511-9355-4c36-80a1-bebfe48a08f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 77940\n",
            "Valid size: 15588\n",
            "Test size: 53454\n",
            "Meta size: 205\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import glob\n",
        "from pandas.core.common import flatten\n",
        "import random\n",
        "\n",
        "separator = '/'\n",
        "\n",
        "train_data_path = 'datasets' + separator + 'Train'\n",
        "test_data_path = 'datasets' + separator + 'Test'\n",
        "meta_data_path = 'datasets' + separator + 'Meta'\n",
        "\n",
        "train_image_paths = []\n",
        "classes = []\n",
        "\n",
        "for data_path in glob.glob(train_data_path + separator + '*'):\n",
        "    classes.append(data_path.split(separator)[-1])\n",
        "    train_image_paths.append(glob.glob(data_path + separator + '*'))\n",
        "\n",
        "train_image_paths = list(flatten(train_image_paths))\n",
        "random.shuffle(train_image_paths)\n",
        "\n",
        "train_image_paths = train_image_paths[:int(0.8 * len(train_image_paths))]\n",
        "valid_image_paths = train_image_paths[int(0.8 * len(train_image_paths)):]\n",
        "\n",
        "test_image_paths = []\n",
        "for data_path in glob.glob(test_data_path + separator + '*'):\n",
        "    test_image_paths.append(glob.glob(data_path + separator + '*'))\n",
        "\n",
        "test_image_paths = list(flatten(test_image_paths))\n",
        "\n",
        "meta_image_paths = [glob.glob(meta_data_path + separator + '*')]\n",
        "meta_image_paths = list(flatten(meta_image_paths))\n",
        "\n",
        "print('Train size:', len(train_image_paths))\n",
        "print('Valid size:', len(valid_image_paths))\n",
        "print('Test size:', len(test_image_paths))\n",
        "print('Meta size:', len(meta_image_paths))\n",
        "\n",
        "idx_to_class = {i: j for i, j in enumerate(classes)}\n",
        "class_to_idx = {value: key for key, value in idx_to_class.items()}\n",
        "\n",
        "\n",
        "class TrafficSignalDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.image_paths[idx]\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        label = image_filepath.split(separator)[-2]\n",
        "        label = class_to_idx[label]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-GmLiF43wcK"
      },
      "source": [
        "Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhjtVPbk3xRW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def plot_stuff(cost, acc):\n",
        "    fig, ax1 = plt.subplots()\n",
        "    color = 'tab:red'\n",
        "    ax1.plot(cost, color=color)\n",
        "    ax1.set_xlabel('Iteration', color=color)\n",
        "    ax1.set_ylabel('total loss', color=color)\n",
        "    ax1.tick_params(axis='y', color=color)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel('accuracy', color=color)\n",
        "    ax2.plot(acc, color=color)\n",
        "    ax2.tick_params(axis='y', color=color)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def imshow_(inp, title=None):\n",
        "    inp = inp.permute(1, 2, 0).numpy()\n",
        "    print(inp.shape)\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def result(model, x, y):\n",
        "    z = model(x.unsqueeze_(0))\n",
        "    _, yhat = torch.max(z.data, 1)\n",
        "\n",
        "    if yhat.item() != y:\n",
        "        text = \"predicted: {} actual: {}\".format(str(yhat.item()), y)\n",
        "        print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOtbfDHJ30MA"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLbuWwDk31Kn"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    n_epochs,\n",
        "    n_test,\n",
        "    scheduler,\n",
        "    device,\n",
        "    print_=True\n",
        "):\n",
        "    loss_list = []\n",
        "    accuracy_list = []\n",
        "    accuracy_best = 0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        loss_sublist = []\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            model.train()\n",
        "\n",
        "            z = model(x)\n",
        "            loss = criterion(z, y)\n",
        "            loss_sublist.append(loss.data.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(\"epoch {} done\".format(epoch))\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        loss_list.append(np.mean(loss_sublist))\n",
        "        correct = 0\n",
        "\n",
        "        for x_test, y_test in valid_loader:\n",
        "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "            model.eval()\n",
        "            z = model(x_test)\n",
        "            _, yhat = torch.max(z.data, 1)\n",
        "            correct += (yhat == y_test).sum().item()\n",
        "        accuracy = correct / n_test\n",
        "        accuracy_list.append(accuracy)\n",
        "        if accuracy > accuracy_best:\n",
        "            accuracy_best = accuracy\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        if print_:\n",
        "            print()\n",
        "            print('Learning rate', optimizer.param_groups[0]['lr'])\n",
        "            print(\"Validation cost for epoch \" + str(epoch + 1) + \": \" + str(np.mean(loss_sublist)))\n",
        "            print(\"Validation accuracy for epoch \" + str(epoch + 1) + \": \" + str(accuracy))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return accuracy_list, loss_list, model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMYwlvfX33G4"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "378e8af79cc748349da1a7d01773f790",
            "0510c60f24804c9c9f9b2bc224674b49",
            "25583395c0c14a3b96464c10c2b93891",
            "7d8b9c8c1d7b463482345320f3da62e2",
            "2ab5021d30494fc0a8c85472db222973",
            "a4be50532d18407ca7d9a180b26d1e0f",
            "fd17a05adac64986a6c5d7ba55565821",
            "e036984f3b094574a7cd5adc4b416e93",
            "a97e04f69fc54fd9aea1e21e13c4aa98",
            "e41dfcf72d344f85bf8d07121177708c",
            "a6bbe1e773814c7d963ae6faeb183f96"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UTl8dSRi33xh",
        "outputId": "bafd23ce-8546-4537-e165-a66a83f001b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The device type is cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/230M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "378e8af79cc748349da1a7d01773f790"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [24:41<3:42:12, 1481.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.002800000000000002\n",
            "Validation cost for epoch 1: 3.1969727154435783\n",
            "Validation accuracy for epoch 1: 0.5356043110084681\n",
            "epoch 1 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [48:40<3:14:12, 1456.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.0046\n",
            "Validation cost for epoch 2: 1.5700262555935112\n",
            "Validation accuracy for epoch 2: 0.7798947908647678\n",
            "epoch 2 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [1:12:56<2:49:54, 1456.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.006400000000000001\n",
            "Validation cost for epoch 3: 0.920259053850996\n",
            "Validation accuracy for epoch 3: 0.8576469078778548\n",
            "epoch 3 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [1:37:02<2:25:14, 1452.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.008199999999999999\n",
            "Validation cost for epoch 4: 0.6511427443015751\n",
            "Validation accuracy for epoch 4: 0.8929946112394149\n",
            "epoch 4 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [2:01:05<2:00:43, 1448.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.010000000000000002\n",
            "Validation cost for epoch 5: 0.5123335586980059\n",
            "Validation accuracy for epoch 5: 0.9162176032845779\n",
            "epoch 5 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [2:25:08<1:36:27, 1446.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.008199999999999999\n",
            "Validation cost for epoch 6: 0.42863988865332064\n",
            "Validation accuracy for epoch 6: 0.9245573518090839\n",
            "epoch 6 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [2:49:09<1:12:14, 1444.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.006400000000000001\n",
            "Validation cost for epoch 7: 0.37219004370945036\n",
            "Validation accuracy for epoch 7: 0.9314857582755967\n",
            "epoch 7 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [3:13:02<48:02, 1441.20s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.0046\n",
            "Validation cost for epoch 8: 0.334225694473056\n",
            "Validation accuracy for epoch 8: 0.9424557351809084\n",
            "epoch 8 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [3:36:56<23:58, 1438.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.002800000000000002\n",
            "Validation cost for epoch 9: 0.3108125444263073\n",
            "Validation accuracy for epoch 9: 0.9467539132666154\n",
            "epoch 9 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [4:00:56<00:00, 1445.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learning rate 0.001\n",
            "Validation cost for epoch 10: 0.29181673818180714\n",
            "Validation accuracy for epoch 10: 0.9455991788555299\n",
            "Elapsed time: 14456.811325788498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Hyper-parameters\n",
        "n_epochs = 10\n",
        "batch_size = 64\n",
        "lr = 0.000001\n",
        "momentum = 0.9\n",
        "lr_scheduler = True\n",
        "base_lr = 0.001\n",
        "max_lr = 0.01\n",
        "n_neurons = 2048\n",
        "\n",
        "n_classes = len(meta_image_paths)\n",
        "\n",
        "train_set = TrafficSignalDataset(train_image_paths, train_transforms)\n",
        "valid_set = TrafficSignalDataset(valid_image_paths, test_transforms)\n",
        "test_set = TrafficSignalDataset(test_image_paths, test_transforms)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_set, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"The device type is\", device)\n",
        "\n",
        "model = models.resnet152(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(n_neurons, n_classes)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "if lr_scheduler:\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
        "        optimizer,\n",
        "        base_lr=base_lr,\n",
        "        max_lr=max_lr,\n",
        "        step_size_up=5,\n",
        "        mode=\"triangular2\"\n",
        "    )\n",
        "else:\n",
        "    scheduler = None\n",
        "\n",
        "start_datetime = datetime.now()\n",
        "start_time = time.time()\n",
        "\n",
        "accuracy_list, loss_list, model = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    n_epochs=n_epochs,\n",
        "    n_test=len(valid_set),\n",
        "    scheduler=scheduler,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "end_datetime = datetime.now()\n",
        "current_time = time.time()\n",
        "elapsed_time = current_time - start_time\n",
        "print(\"Elapsed time:\", elapsed_time)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VkG20JJ3-u7"
      },
      "source": [
        "Result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Xaoc_2Kd0xB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T9jMOBp3_XK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb634305-fa9f-4a35-ecc8-276a2875f909"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (23): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (24): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (25): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (26): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (27): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (28): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (29): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (30): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (31): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (32): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (33): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (34): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (35): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=205, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "filename = 'model152.pt'\n",
        "\n",
        "torch.save(model.state_dict(), filename)\n",
        "! mv $filename drive/MyDrive/$filename\n",
        "plot_stuff(loss_list, accuracy_list)\n",
        "\n",
        "model = models.resnet152(pretrained=True)\n",
        "model.fc = nn.Linear(n_neurons, n_classes)\n",
        "model.load_state_dict(torch.load('drive/MyDrive/' + filename))\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "378e8af79cc748349da1a7d01773f790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0510c60f24804c9c9f9b2bc224674b49",
              "IPY_MODEL_25583395c0c14a3b96464c10c2b93891",
              "IPY_MODEL_7d8b9c8c1d7b463482345320f3da62e2"
            ],
            "layout": "IPY_MODEL_2ab5021d30494fc0a8c85472db222973"
          }
        },
        "0510c60f24804c9c9f9b2bc224674b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4be50532d18407ca7d9a180b26d1e0f",
            "placeholder": "​",
            "style": "IPY_MODEL_fd17a05adac64986a6c5d7ba55565821",
            "value": "100%"
          }
        },
        "25583395c0c14a3b96464c10c2b93891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e036984f3b094574a7cd5adc4b416e93",
            "max": 241627721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a97e04f69fc54fd9aea1e21e13c4aa98",
            "value": 241627721
          }
        },
        "7d8b9c8c1d7b463482345320f3da62e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41dfcf72d344f85bf8d07121177708c",
            "placeholder": "​",
            "style": "IPY_MODEL_a6bbe1e773814c7d963ae6faeb183f96",
            "value": " 230M/230M [00:01&lt;00:00, 165MB/s]"
          }
        },
        "2ab5021d30494fc0a8c85472db222973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4be50532d18407ca7d9a180b26d1e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd17a05adac64986a6c5d7ba55565821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e036984f3b094574a7cd5adc4b416e93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97e04f69fc54fd9aea1e21e13c4aa98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e41dfcf72d344f85bf8d07121177708c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6bbe1e773814c7d963ae6faeb183f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}